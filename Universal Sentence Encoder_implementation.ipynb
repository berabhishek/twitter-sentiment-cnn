{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "oyjTE5zYjYRD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from tqdm import tqdm\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J9ffeK7Ujqbj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "random.seed(1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sCnembupjsW9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "tokenizer = RegexpTokenizer('[a-zA-Z0-9]\\w+')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kLjUHvVSju56",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "positive = []\n",
        "negative = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hBbn8nFwjxNt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('pos.txt', 'r', buffering = 1000, encoding=\"ISO-8859–1\") as p:\n",
        "    positive = p.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tn4nwhvqjz1o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('neg.txt', 'r', buffering = 1000, encoding=\"ISO-8859–1\") as n:\n",
        "    negative = n.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SWt2NWcZj6RK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### As, generating labels for the whole 1600000 tweets is taking around 8hrs on Google Collab GPU, I had to reduce the dataset to a max of 400000 tweets."
      ]
    },
    {
      "metadata": {
        "id": "wNaM_2lyj279",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "positive = positive[:200000]\n",
        "negative = negative[:200000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PmxyJJPXkAF5",
        "colab_type": "code",
        "outputId": "a186b529-3e4f-4d11-b3d8-527568982bb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print('Shuffling tweets to maintain randomness....')\n",
        "unclean_tweets = list(positive) + list(negative)\n",
        "random.shuffle(unclean_tweets)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shuffling tweets to maintain randomness....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pZxp1EoAwwEk",
        "colab_type": "code",
        "outputId": "ccb13ad0-5c5a-4f98-886d-b9846388710b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(unclean_tweets)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "1Ooi7IlIkDKI",
        "colab_type": "code",
        "outputId": "db9e54d7-c77b-48f9-a246-8187d6784238",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print('Generate labels...')\n",
        "labels = []\n",
        "with tqdm(total = len(unclean_tweets)) as pb:\n",
        "    for tweet in unclean_tweets:\n",
        "        if tweet in positive:\n",
        "            labels.append(1)\n",
        "        else:\n",
        "            labels.append(0)\n",
        "        pb.update(1)\n",
        "del positive\n",
        "del negative"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 24/400000 [00:00<28:18, 235.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generate labels...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 400000/400000 [23:05<00:00, 288.69it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "LqloA3O9kFrb",
        "colab_type": "code",
        "outputId": "42407e27-f890-47a8-a0a0-a723ae1567dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "unclean_tweets[:5]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"There're some great Twitter apps for Mac. How much I miss my hackintosh installation.\",\n",
              " '<< Right there Lyrics for Chocolate n Cream',\n",
              " 'Does not want to go to school tomorrow',\n",
              " \"Didn't get not one of your bbm's My phone sucks!\",\n",
              " 'yeah i do.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "HTlXD7skkIjd",
        "colab_type": "code",
        "outputId": "f122b26b-2d8b-494d-ca12-5f891ce47a45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tweet-preprocessor"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tweet-preprocessor in /usr/local/lib/python3.6/dist-packages (0.5.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5wlHpwOkkLDp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# tweet preprocessor to eliminate emoji, url and mentions\n",
        "import preprocessor as p\n",
        "p.set_options(p.OPT.URL, p.OPT.EMOJI, p.OPT.MENTION)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ue6fl0iskQY6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Cleaning tweets\n",
        "1. Remove emoji\n",
        "2. Remove URLs\n",
        "3. Remove mentions"
      ]
    },
    {
      "metadata": {
        "id": "x38b1QL2kNjC",
        "colab_type": "code",
        "outputId": "33a97ee4-358c-4ebc-9a26-5a082bc85fb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "with tqdm(total = len(unclean_tweets)) as pb:\n",
        "    for i in range(len(unclean_tweets)):\n",
        "      tweet_unclean = unclean_tweets[i]\n",
        "      unclean_tweets[i] = p.clean(tweet_unclean)\n",
        "      pb.update(1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 400000/400000 [00:19<00:00, 20998.01it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "2yV6DRgokW1u",
        "colab_type": "code",
        "outputId": "01af8b8f-7e01-4f78-897d-2bd0d5c8e231",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "unclean_tweets[:5]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"There're some great Twitter apps for Mac. How much I miss my hackintosh installation.\",\n",
              " '<< Right there Lyrics for Chocolate n Cream',\n",
              " 'Does not want to go to school tomorrow',\n",
              " \"Didn't get not one of your bbm's My phone sucks!\",\n",
              " 'yeah i do.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "jc0kOg3IkaIM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### We see that there are certain tweets where the HTML encoding has not been converted into text. Eg: &amp, &quot\n",
        "### So, here I will use BeautifulSoup"
      ]
    },
    {
      "metadata": {
        "id": "kyRpGxLqkXmR",
        "colab_type": "code",
        "outputId": "e63244e0-e213-4914-a050-c61e8a49546b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "sample = BeautifulSoup(\"lots'olaughs w/Katrina, Jackie, Sandra&amp;Angelo &quot;HOT DAMN!&quot;\")\n",
        "sample.get_text()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'lots\\'olaughs w/Katrina, Jackie, Sandra&Angelo \"HOT DAMN!\"'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "yGnKde6kkfOJ",
        "colab_type": "code",
        "outputId": "ae8fd12b-a650-48fe-f550-f4ad28d89897",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "with tqdm(total = len(unclean_tweets)) as pb:\n",
        "    for i in range(len(unclean_tweets)):\n",
        "      tweet_unclean = unclean_tweets[i]\n",
        "      unclean_tweets[i] = BeautifulSoup(tweet_unclean).get_text()\n",
        "      pb.update(1)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 41%|████      | 163589/400000 [00:12<00:17, 13366.07it/s]/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:273: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
            "  ' Beautiful Soup.' % markup)\n",
            "100%|██████████| 400000/400000 [00:31<00:00, 12655.81it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nNMsp6S2khZi",
        "colab_type": "code",
        "outputId": "3f3d3d6d-a8ea-40a9-bd86-3c701c61811b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "unclean_tweets[:5]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"There're some great Twitter apps for Mac. How much I miss my hackintosh installation.\",\n",
              " '<< Right there Lyrics for Chocolate n Cream',\n",
              " 'Does not want to go to school tomorrow',\n",
              " \"Didn't get not one of your bbm's My phone sucks!\",\n",
              " 'yeah i do.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "myXFCj02kjbf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Tokenizing tweets"
      ]
    },
    {
      "metadata": {
        "id": "4QNqmR8xkmaW",
        "colab_type": "code",
        "outputId": "ed914eec-583b-47cb-fc87-033203a32f6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print('Tokenizing ..')\n",
        "tweets = [tokenizer.tokenize(tweet.lower()) for tweet in unclean_tweets]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenizing ..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DahAz6SCkpTv",
        "colab_type": "code",
        "outputId": "c3befee9-b42e-4362-a156-b2e5971b510e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "tweets[:2]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['there',\n",
              "  're',\n",
              "  'some',\n",
              "  'great',\n",
              "  'twitter',\n",
              "  'apps',\n",
              "  'for',\n",
              "  'mac',\n",
              "  'how',\n",
              "  'much',\n",
              "  'miss',\n",
              "  'my',\n",
              "  'hackintosh',\n",
              "  'installation'],\n",
              " ['right', 'there', 'lyrics', 'for', 'chocolate', 'cream']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "tkw3VsqiktNN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Lemmatizing"
      ]
    },
    {
      "metadata": {
        "id": "4AzDMA2rkumF",
        "colab_type": "code",
        "outputId": "d93ce053-c492-4870-dfe8-d2fd483e0013",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "XmUr1IO2kxxO",
        "colab_type": "code",
        "outputId": "1137890d-c3b8-4cda-f4d8-66054718d77f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "tweets = []\n",
        "with tqdm(total=len(unclean_tweets)) as pb:\n",
        "    for tweet in unclean_tweets:\n",
        "        lemmatized = [lemmatizer.lemmatize(word) for word in tweet]\n",
        "        tweets.append(lemmatized)\n",
        "        pb.update(1)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 400000/400000 [02:12<00:00, 3011.05it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "cEYd-jdhNF3C",
        "colab_type": "code",
        "outputId": "72da4597-e6b4-4446-cb00-54de5f57395d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-hub tensorflow numpy pickle tqdm keras"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.6/dist-packages (0.1.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.14.6)\n",
            "Collecting pickle\n",
            "\u001b[31m  Could not find a version that satisfies the requirement pickle (from versions: )\u001b[0m\n",
            "\u001b[31mNo matching distribution found for pickle\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lyl2FR8sk0Kl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Universal Sentence Encoder for word embeddings"
      ]
    },
    {
      "metadata": {
        "id": "TW08VmnUk5RF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "embed = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder/1\")\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "  tweet_embeddings = sess.run(embed(tweets))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sdukV0KGNP1h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E_xmHNNalAZm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "1c7e0491-a3f8-41da-d21f-db076c3554b9"
      },
      "cell_type": "code",
      "source": [
        "tweet_embeddings = np.array(tweet_embeddings)\n",
        "tweet_embeddings.shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-7200bdab8dd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtweet_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtweet_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tweet_embeddings' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "5h05GF0glDaG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tweet_embeddings = np.array([np.reshape(embed, (len(embed), 1)) for embed in tweet_embeddings])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kShp9eFQlIdw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tweet_embeddings.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8xhdhUOllP7J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### One-hot labels"
      ]
    },
    {
      "metadata": {
        "id": "M1od5fxL4m7E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "labels_one_hot = []\n",
        "\n",
        "with tqdm(total=len(labels)) as pbar:\n",
        "  for label in labels:\n",
        "    if label == 0:\n",
        "      labels_one_hot.append([1., 0.])\n",
        "    else:\n",
        "      labels_one_hot.append([0., 1.])\n",
        "      \n",
        "    pbar.update(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U__u0_-YlLBd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "labels_one_hot = np.array(labels_one_hot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xbLipQLOwnZG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Pickling all data"
      ]
    },
    {
      "metadata": {
        "id": "IwFw070rlc1q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "embeddings_file = \"embeddings-{}.pickle\".format(len(tweet_embeddings))\n",
        "labels_file = \"labels-{}.pickle\".format(len(labels))\n",
        "\n",
        "pickle.dump(tweet_embeddings, open(embeddings_file, 'wb'))\n",
        "pickle.dump(labels_one_hot, open(labels_file, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NP2K2bJWld5l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "labels_one_hot.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SHxJkPJSlg5Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Loading data"
      ]
    },
    {
      "metadata": {
        "id": "8Jb3O1W6liYc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "tweet_embeddings = pickle.load(open('tweets_embeddings.pickle', 'rb'))\n",
        "labels = pickle.load(open('labels-one_hot.pickle', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TRy8zYwnw-x9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Dataset partition"
      ]
    },
    {
      "metadata": {
        "id": "0LdGe0LPlmVn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wB78sA4ixHy1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(tweet_embeddings, labels, test_size=.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LNpQ7TG-xSRG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "x_test = np.array(x_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IlqAhpMIxVQS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vector_size = 512\n",
        "batch_size = 500\n",
        "no_epochs = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z_IN__rNxWJj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Build the model"
      ]
    },
    {
      "metadata": {
        "id": "VCDDi5IklqBj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, batch_size=batch_size, shuffle=True, epochs=no_epochs,\n",
        "         validation_data=(x_test, y_test), callbacks=[tensorboard, EarlyStopping(min_delta=0.0001, patience=3)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "si1Nz-xOxroD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, Dropout, Dense, Flatten, LSTM, MaxPooling1D, Bidirectional\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, TensorBoard\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(32, kernel_size=3, activation='elu', padding='same',\n",
        "                 input_shape=(vector_size, 1)))\n",
        "model.add(Conv1D(32, kernel_size=3, activation='elu', padding='same'))\n",
        "model.add(Conv1D(32, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(MaxPooling1D(pool_size=3))\n",
        "\n",
        "model.add(Bidirectional(LSTM(512, dropout=0.2, recurrent_dropout=0.3)))\n",
        "\n",
        "model.add(Dense(512, activation='sigmoid'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='sigmoid'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(512, activation='sigmoid'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])\n",
        "\n",
        "tensorboard = TensorBoard(log_dir='logs/', histogram_freq=0, write_graph=True, write_images=True)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uT3tyjvyxwv7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(np.array(x_train), np.array(y_train), batch_size=batch_size, epochs=no_epochs,\n",
        "         validation_data=(np.array(x_test), np.array(y_test)), callbacks=[tensorboard, EarlyStopping(min_delta=0.0001, patience=3)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s50v1yNylvvf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model evaluation"
      ]
    },
    {
      "metadata": {
        "id": "8mtZBkcQlsmg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.metrics_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1YZgmTVglyG6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.evaluate(x=x_test, y=y_test, batch_size=500, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ruGMzefol3FV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Save the model"
      ]
    },
    {
      "metadata": {
        "id": "thIoBivbl4Rl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('universal-sentence-encoder-400k.model')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}