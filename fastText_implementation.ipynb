{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "d7291db5-ad83-43bd-c1a1-0c083445ec5f",
        "id": "twfj1I3qqhSp",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-03854340-9978-46e4-9130-d271646aef46\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-03854340-9978-46e4-9130-d271646aef46\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving pos.txt to pos.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oyjTE5zYjYRD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from tqdm import tqdm\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J9ffeK7Ujqbj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "random.seed(1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sCnembupjsW9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "tokenizer = RegexpTokenizer('[a-zA-Z0-9]\\w+')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kLjUHvVSju56",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "positive = []\n",
        "negative = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hBbn8nFwjxNt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('pos.txt', 'r', buffering = 1000, encoding=\"ISO-8859–1\") as p:\n",
        "    positive = p.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tn4nwhvqjz1o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('neg.txt', 'r', buffering = 1000, encoding=\"ISO-8859–1\") as n:\n",
        "    negative = n.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SWt2NWcZj6RK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### As, generating labels for the whole 1600000 tweets is taking around 8hrs on Google Collab GPU, I had to reduce the dataset to a max of 400000 tweets."
      ]
    },
    {
      "metadata": {
        "id": "wNaM_2lyj279",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "positive = positive[:200000]\n",
        "negative = negative[:200000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PmxyJJPXkAF5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "490413e1-ac76-4a9c-d378-f8e5140f4407"
      },
      "cell_type": "code",
      "source": [
        "print('Shuffling tweets to maintain randomness....')\n",
        "unclean_tweets = list(positive) + list(negative)\n",
        "random.shuffle(unclean_tweets)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shuffling tweets to maintain randomness....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pZxp1EoAwwEk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a4100661-9f20-4798-eaba-f2ced45fec62"
      },
      "cell_type": "code",
      "source": [
        "len(unclean_tweets)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "metadata": {
        "id": "1Ooi7IlIkDKI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fb656001-d519-4605-86b7-b43df10f93e9"
      },
      "cell_type": "code",
      "source": [
        "print('Generate labels...')\n",
        "labels = []\n",
        "with tqdm(total = len(unclean_tweets)) as pb:\n",
        "    for tweet in unclean_tweets:\n",
        "        if tweet in positive:\n",
        "            labels.append(1)\n",
        "        else:\n",
        "            labels.append(0)\n",
        "        pb.update(1)\n",
        "del positive\n",
        "del negative"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 56/400000 [00:00<12:03, 552.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generate labels...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 400000/400000 [14:24<00:00, 462.83it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "LqloA3O9kFrb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ec5a8f2d-dc37-45f3-891c-09e465052fe6"
      },
      "cell_type": "code",
      "source": [
        "unclean_tweets[:5]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@GoldyMom oh we are near the sawgrass mills mall area \\n',\n",
              " \"I don't want to apply for jobs!!!  \\n\",\n",
              " \"@butterflykate Who've u noticed now Kate ? \\n\",\n",
              " 'The furry ones and I were gonna go back 2 the bark park today. But its ElCrapo outside \\n',\n",
              " \"@leenkwan haha edz is too lame d i dunno wat to say. im so tempted to get another bunny! they're too cute! go check ur email babe \\n\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "HTlXD7skkIjd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d83d1c18-ca0a-4668-9535-5f16722dead3"
      },
      "cell_type": "code",
      "source": [
        "!pip install tweet-preprocessor"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tweet-preprocessor in /usr/local/lib/python3.6/dist-packages (0.5.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5wlHpwOkkLDp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# tweet preprocessor to eliminate emoji, url and mentions\n",
        "import preprocessor as p\n",
        "p.set_options(p.OPT.URL, p.OPT.EMOJI, p.OPT.MENTION)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ue6fl0iskQY6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Cleaning tweets\n",
        "1. Remove emoji\n",
        "2. Remove URLs\n",
        "3. Remove mentions"
      ]
    },
    {
      "metadata": {
        "id": "x38b1QL2kNjC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9a42e5f-cb17-4ff9-c683-8d09f0d31a16"
      },
      "cell_type": "code",
      "source": [
        "with tqdm(total = len(unclean_tweets)) as pb:\n",
        "    for i in range(len(unclean_tweets)):\n",
        "      tweet_unclean = unclean_tweets[i]\n",
        "      unclean_tweets[i] = p.clean(tweet_unclean)\n",
        "      pb.update(1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 400000/400000 [00:20<00:00, 19766.90it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "2yV6DRgokW1u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ec319e2e-86c0-4723-92fb-1ecd33806215"
      },
      "cell_type": "code",
      "source": [
        "unclean_tweets[:5]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['oh we are near the sawgrass mills mall area',\n",
              " \"I don't want to apply for jobs!!!\",\n",
              " \"Who've u noticed now Kate ?\",\n",
              " 'The furry ones and I were gonna go back 2 the bark park today. But its ElCrapo outside',\n",
              " \"haha edz is too lame d i dunno wat to say. im so tempted to get another bunny! they're too cute! go check ur email babe\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "jc0kOg3IkaIM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### We see that there are certain tweets where the HTML encoding has not been converted into text. Eg: &amp, &quot\n",
        "### So, here I will use BeautifulSoup"
      ]
    },
    {
      "metadata": {
        "id": "kyRpGxLqkXmR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ef07e3e-4c06-4abe-d2b1-0496eae02644"
      },
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "sample = BeautifulSoup(\"lots'olaughs w/Katrina, Jackie, Sandra&amp;Angelo &quot;HOT DAMN!&quot;\")\n",
        "sample.get_text()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'lots\\'olaughs w/Katrina, Jackie, Sandra&Angelo \"HOT DAMN!\"'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "yGnKde6kkfOJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "01e7243f-f8b4-41bd-dec9-71344d23e8d1"
      },
      "cell_type": "code",
      "source": [
        "with tqdm(total = len(unclean_tweets)) as pb:\n",
        "    for i in range(len(unclean_tweets)):\n",
        "      tweet_unclean = unclean_tweets[i]\n",
        "      unclean_tweets[i] = BeautifulSoup(tweet_unclean).get_text()\n",
        "      pb.update(1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 20%|█▉        | 78581/400000 [00:08<00:33, 9736.43it/s]/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:273: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
            "  ' Beautiful Soup.' % markup)\n",
            "100%|██████████| 400000/400000 [00:41<00:00, 9593.77it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nNMsp6S2khZi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "c5df3628-c0e4-4b3a-a027-05e3c7e7e33f"
      },
      "cell_type": "code",
      "source": [
        "unclean_tweets[:5]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['oh we are near the sawgrass mills mall area',\n",
              " \"I don't want to apply for jobs!!!\",\n",
              " \"Who've u noticed now Kate ?\",\n",
              " 'The furry ones and I were gonna go back 2 the bark park today. But its ElCrapo outside',\n",
              " \"haha edz is too lame d i dunno wat to say. im so tempted to get another bunny! they're too cute! go check ur email babe\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "myXFCj02kjbf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Tokenizing tweets"
      ]
    },
    {
      "metadata": {
        "id": "4QNqmR8xkmaW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2d8d6c80-70a2-4d04-d651-e77d542e8772"
      },
      "cell_type": "code",
      "source": [
        "print('Tokenizing ..')\n",
        "tweets = [tokenizer.tokenize(tweet.lower()) for tweet in unclean_tweets]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenizing ..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DahAz6SCkpTv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f6b16c80-fe15-4b22-fd13-ab815e7609c3"
      },
      "cell_type": "code",
      "source": [
        "tweets[:2]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['oh', 'we', 'are', 'near', 'the', 'sawgrass', 'mills', 'mall', 'area'],\n",
              " ['don', 'want', 'to', 'apply', 'for', 'jobs']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "tkw3VsqiktNN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Lemmatizing"
      ]
    },
    {
      "metadata": {
        "id": "4AzDMA2rkumF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "fbd90611-32b8-4453-de52-9b1f359f2b55"
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "XmUr1IO2kxxO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "119ead0b-b764-46bd-9774-439e544ec874"
      },
      "cell_type": "code",
      "source": [
        "tweets = []\n",
        "with tqdm(total=len(unclean_tweets)) as pb:\n",
        "    for tweet in unclean_tweets:\n",
        "        lemmatized = [lemmatizer.lemmatize(word) for word in tweet]\n",
        "        tweets.append(lemmatized)\n",
        "        pb.update(1)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 400000/400000 [02:11<00:00, 3043.21it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "lyl2FR8sk0Kl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### FastText (Gensim) for word embeddings"
      ]
    },
    {
      "metadata": {
        "id": "TW08VmnUk5RF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vector_size = 256\n",
        "window = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZnOjwWzT2rU4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "4a1fdbbc-8a55-4e77-c540-9e9a5e400c92"
      },
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.6)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.1.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.7.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.50)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (0.98)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.3)\n",
            "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.1.13)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.50 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.50)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.10.15)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.50->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.50->boto3->smart-open>=1.2.1->gensim) (0.14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E_xmHNNalAZm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a26ebcac-d432-4f91-a316-2947cbc974d3"
      },
      "cell_type": "code",
      "source": [
        "from gensim.models import FastText\n",
        "\n",
        "import time\n",
        "\n",
        "fasttext_model = 'fasttext.model'\n",
        "\n",
        "print('Generating FastText Vectors ..')\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "model = FastText(size=vector_size)\n",
        "model.build_vocab(tweets)\n",
        "model.train(tweets, window=window, min_count=1, workers=4, total_examples=model.corpus_count,\n",
        "           epochs=model.epochs)\n",
        "\n",
        "print('FastText Created in {} seconds.'.format(time.time() - start))\n",
        "\n",
        "model.save(fasttext_model)\n",
        "print('FastText Model saved at {}'.format(fasttext_model))\n",
        "\n",
        "del model"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating FastText Vectors ..\n",
            "FastText Created in 75.7538697719574 seconds.\n",
            "FastText Model saved at fasttext.model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5h05GF0glDaG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = FastText.load(fasttext_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kShp9eFQlIdw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_vectors = model.wv\n",
        "del model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8xhdhUOllP7J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test and train spilt"
      ]
    },
    {
      "metadata": {
        "id": "M1od5fxL4m7E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "faf2490a-fd0f-4582-e952-c6fda7f03c9a"
      },
      "cell_type": "code",
      "source": [
        "len(tweets)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "U__u0_-YlLBd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb6327f3-2e96-4aa9-cec4-57c98fc0d324"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras.backend as K\n",
        "\n",
        "train_size = int(0.9*(len(tweets)))\n",
        "test_size = int(0.1*(len(tweets)))\n",
        "\n",
        "max_no_tokens = 15\n",
        "\n",
        "indexes = set(np.random.choice(len(tweets), train_size + test_size, replace=False))\n",
        "\n",
        "x_train = np.zeros((train_size, max_no_tokens, vector_size), dtype=K.floatx())\n",
        "y_train = np.zeros((train_size, 2), dtype=np.int32)\n",
        "\n",
        "x_test = np.zeros((test_size, max_no_tokens, vector_size), dtype=K.floatx())\n",
        "y_test = np.zeros((test_size, 2), dtype=np.int32)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "IwFw070rlc1q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i, index in enumerate(indexes):\n",
        "    for t, token in enumerate(tweets[index]):\n",
        "        if t >= max_no_tokens:\n",
        "            break\n",
        "      \n",
        "        if token not in x_vectors:\n",
        "            continue\n",
        "    \n",
        "        if i < train_size:\n",
        "            x_train[i, t, :] = x_vectors[token]\n",
        "        else:\n",
        "            x_test[i - train_size, t, :] = x_vectors[token]\n",
        "\n",
        "  \n",
        "    if i < train_size:\n",
        "        y_train[i, :] = [1.0, 0.0] if labels[index] == 0 else [0.0, 1.0]\n",
        "    else:\n",
        "        y_test[i - train_size, :] = [1.0, 0.0] if labels[index] == 0 else [0.0, 1.0]\n",
        "    \n",
        "del tweets\n",
        "del labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NP2K2bJWld5l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6e541d8-11dd-4d74-e797-2a902d07d7d0"
      },
      "cell_type": "code",
      "source": [
        "x_train.shape, y_test.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((360000, 15, 256), (40000, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "SHxJkPJSlg5Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training the model"
      ]
    },
    {
      "metadata": {
        "id": "8Jb3O1W6liYc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 500\n",
        "no_epochs = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0LdGe0LPlmVn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "d4a48c22-196b-4b12-ea0b-6868dc1f462f"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, Dropout, Dense, Flatten, LSTM, MaxPooling1D, Bidirectional\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, TensorBoard\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(32, kernel_size=3, activation='elu', padding='same',\n",
        "                 input_shape=(max_no_tokens, vector_size)))\n",
        "model.add(Conv1D(32, kernel_size=3, activation='elu', padding='same'))\n",
        "model.add(Conv1D(32, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(MaxPooling1D(pool_size=3))\n",
        "\n",
        "model.add(Bidirectional(LSTM(512, dropout=0.2, recurrent_dropout=0.3)))\n",
        "\n",
        "model.add(Dense(512, activation='sigmoid'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='sigmoid'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(512, activation='sigmoid'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])\n",
        "\n",
        "tensorboard = TensorBoard(log_dir='logs/', histogram_freq=0, write_graph=True, write_images=True)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_1 (Conv1D)            (None, 15, 32)            24608     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 15, 32)            3104      \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 15, 32)            3104      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 5, 32)             0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 1024)              2232320   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 3,314,274\n",
            "Trainable params: 3,314,274\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VCDDi5IklqBj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1499
        },
        "outputId": "edd1e91e-15ce-4193-f6c4-aa8a166fd668"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, batch_size=batch_size, shuffle=True, epochs=no_epochs,\n",
        "         validation_data=(x_test, y_test), callbacks=[tensorboard, EarlyStopping(min_delta=0.0001, patience=3)])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 360000 samples, validate on 40000 samples\n",
            "Epoch 1/100\n",
            "360000/360000 [==============================] - 62s 172us/step - loss: 0.6972 - acc: 0.5546 - val_loss: 0.6564 - val_acc: 0.6105\n",
            "Epoch 2/100\n",
            "360000/360000 [==============================] - 58s 161us/step - loss: 0.6563 - acc: 0.6123 - val_loss: 0.6417 - val_acc: 0.6284\n",
            "Epoch 3/100\n",
            "360000/360000 [==============================] - 59s 163us/step - loss: 0.6434 - acc: 0.6252 - val_loss: 0.6342 - val_acc: 0.6357\n",
            "Epoch 4/100\n",
            "360000/360000 [==============================] - 59s 164us/step - loss: 0.6361 - acc: 0.6337 - val_loss: 0.6318 - val_acc: 0.6388\n",
            "Epoch 5/100\n",
            "360000/360000 [==============================] - 58s 161us/step - loss: 0.6305 - acc: 0.6395 - val_loss: 0.6256 - val_acc: 0.6422\n",
            "Epoch 6/100\n",
            "360000/360000 [==============================] - 59s 164us/step - loss: 0.6275 - acc: 0.6424 - val_loss: 0.6234 - val_acc: 0.6445\n",
            "Epoch 7/100\n",
            "360000/360000 [==============================] - 58s 162us/step - loss: 0.6237 - acc: 0.6464 - val_loss: 0.6196 - val_acc: 0.6493\n",
            "Epoch 8/100\n",
            "360000/360000 [==============================] - 58s 161us/step - loss: 0.6207 - acc: 0.6497 - val_loss: 0.6192 - val_acc: 0.6497\n",
            "Epoch 9/100\n",
            "360000/360000 [==============================] - 58s 162us/step - loss: 0.6186 - acc: 0.6524 - val_loss: 0.6167 - val_acc: 0.6521\n",
            "Epoch 10/100\n",
            "360000/360000 [==============================] - 59s 164us/step - loss: 0.6166 - acc: 0.6540 - val_loss: 0.6142 - val_acc: 0.6543\n",
            "Epoch 11/100\n",
            "360000/360000 [==============================] - 59s 163us/step - loss: 0.6142 - acc: 0.6554 - val_loss: 0.6134 - val_acc: 0.6563\n",
            "Epoch 12/100\n",
            "360000/360000 [==============================] - 58s 161us/step - loss: 0.6127 - acc: 0.6575 - val_loss: 0.6129 - val_acc: 0.6576\n",
            "Epoch 13/100\n",
            "360000/360000 [==============================] - 59s 164us/step - loss: 0.6110 - acc: 0.6589 - val_loss: 0.6116 - val_acc: 0.6577\n",
            "Epoch 14/100\n",
            "360000/360000 [==============================] - 58s 162us/step - loss: 0.6099 - acc: 0.6602 - val_loss: 0.6108 - val_acc: 0.6574\n",
            "Epoch 15/100\n",
            "360000/360000 [==============================] - 58s 162us/step - loss: 0.6082 - acc: 0.6615 - val_loss: 0.6083 - val_acc: 0.6616\n",
            "Epoch 16/100\n",
            "360000/360000 [==============================] - 58s 162us/step - loss: 0.6069 - acc: 0.6627 - val_loss: 0.6080 - val_acc: 0.6621\n",
            "Epoch 17/100\n",
            "360000/360000 [==============================] - 59s 164us/step - loss: 0.6057 - acc: 0.6641 - val_loss: 0.6071 - val_acc: 0.6623\n",
            "Epoch 18/100\n",
            "360000/360000 [==============================] - 59s 163us/step - loss: 0.6045 - acc: 0.6648 - val_loss: 0.6064 - val_acc: 0.6645\n",
            "Epoch 19/100\n",
            "360000/360000 [==============================] - 59s 163us/step - loss: 0.6033 - acc: 0.6666 - val_loss: 0.6059 - val_acc: 0.6653\n",
            "Epoch 20/100\n",
            "360000/360000 [==============================] - 59s 164us/step - loss: 0.6023 - acc: 0.6670 - val_loss: 0.6042 - val_acc: 0.6646\n",
            "Epoch 21/100\n",
            "360000/360000 [==============================] - 58s 161us/step - loss: 0.6014 - acc: 0.6682 - val_loss: 0.6058 - val_acc: 0.6630\n",
            "Epoch 22/100\n",
            "360000/360000 [==============================] - 58s 160us/step - loss: 0.6007 - acc: 0.6691 - val_loss: 0.6030 - val_acc: 0.6656\n",
            "Epoch 23/100\n",
            "360000/360000 [==============================] - 58s 162us/step - loss: 0.5997 - acc: 0.6696 - val_loss: 0.6041 - val_acc: 0.6638\n",
            "Epoch 24/100\n",
            "360000/360000 [==============================] - 59s 163us/step - loss: 0.5984 - acc: 0.6707 - val_loss: 0.6024 - val_acc: 0.6678\n",
            "Epoch 25/100\n",
            "360000/360000 [==============================] - 58s 162us/step - loss: 0.5979 - acc: 0.6713 - val_loss: 0.6043 - val_acc: 0.6629\n",
            "Epoch 26/100\n",
            "360000/360000 [==============================] - 59s 163us/step - loss: 0.5972 - acc: 0.6727 - val_loss: 0.6018 - val_acc: 0.6665\n",
            "Epoch 27/100\n",
            "360000/360000 [==============================] - 59s 163us/step - loss: 0.5958 - acc: 0.6731 - val_loss: 0.6010 - val_acc: 0.6701\n",
            "Epoch 28/100\n",
            "360000/360000 [==============================] - 58s 161us/step - loss: 0.5953 - acc: 0.6741 - val_loss: 0.6010 - val_acc: 0.6696\n",
            "Epoch 29/100\n",
            "360000/360000 [==============================] - 58s 162us/step - loss: 0.5950 - acc: 0.6746 - val_loss: 0.5995 - val_acc: 0.6720\n",
            "Epoch 30/100\n",
            "360000/360000 [==============================] - 59s 163us/step - loss: 0.5944 - acc: 0.6751 - val_loss: 0.6009 - val_acc: 0.6677\n",
            "Epoch 31/100\n",
            "360000/360000 [==============================] - 59s 164us/step - loss: 0.5936 - acc: 0.6754 - val_loss: 0.5989 - val_acc: 0.6703\n",
            "Epoch 32/100\n",
            "360000/360000 [==============================] - 58s 160us/step - loss: 0.5933 - acc: 0.6764 - val_loss: 0.5988 - val_acc: 0.6704\n",
            "Epoch 33/100\n",
            "360000/360000 [==============================] - 59s 164us/step - loss: 0.5925 - acc: 0.6767 - val_loss: 0.5977 - val_acc: 0.6710\n",
            "Epoch 34/100\n",
            "360000/360000 [==============================] - 59s 163us/step - loss: 0.5919 - acc: 0.6775 - val_loss: 0.5994 - val_acc: 0.6693\n",
            "Epoch 35/100\n",
            "360000/360000 [==============================] - 58s 161us/step - loss: 0.5912 - acc: 0.6771 - val_loss: 0.5969 - val_acc: 0.6721\n",
            "Epoch 36/100\n",
            "360000/360000 [==============================] - 58s 162us/step - loss: 0.5909 - acc: 0.6784 - val_loss: 0.5979 - val_acc: 0.6711\n",
            "Epoch 37/100\n",
            "360000/360000 [==============================] - 59s 163us/step - loss: 0.5905 - acc: 0.6790 - val_loss: 0.5972 - val_acc: 0.6715\n",
            "Epoch 38/100\n",
            "360000/360000 [==============================] - 59s 163us/step - loss: 0.5898 - acc: 0.6797 - val_loss: 0.5965 - val_acc: 0.6729\n",
            "Epoch 39/100\n",
            "360000/360000 [==============================] - 58s 160us/step - loss: 0.5896 - acc: 0.6799 - val_loss: 0.5951 - val_acc: 0.6738\n",
            "Epoch 40/100\n",
            "360000/360000 [==============================] - 59s 164us/step - loss: 0.5888 - acc: 0.6806 - val_loss: 0.5968 - val_acc: 0.6718\n",
            "Epoch 41/100\n",
            "360000/360000 [==============================] - 59s 163us/step - loss: 0.5884 - acc: 0.6814 - val_loss: 0.6015 - val_acc: 0.6684\n",
            "Epoch 42/100\n",
            "360000/360000 [==============================] - 58s 161us/step - loss: 0.5880 - acc: 0.6817 - val_loss: 0.5979 - val_acc: 0.6712\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8500f1be48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "s50v1yNylvvf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model evaluation"
      ]
    },
    {
      "metadata": {
        "id": "8mtZBkcQlsmg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b48a610-6840-4028-8e4f-037debc9e0ce"
      },
      "cell_type": "code",
      "source": [
        "model.metrics_names"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['loss', 'acc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "1YZgmTVglyG6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a19c5622-0f99-47f4-c598-0e7af6d8c443"
      },
      "cell_type": "code",
      "source": [
        "model.evaluate(x=x_test, y=y_test, batch_size=32, verbose=1)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 24s 612us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5978790123224258, 0.671175]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "ruGMzefol3FV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Save the model"
      ]
    },
    {
      "metadata": {
        "id": "thIoBivbl4Rl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('twitter-sentiment-fasttext.model')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}