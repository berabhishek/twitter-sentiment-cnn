{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GV8TZDgHeR1H"
   },
   "source": [
    "##### Replace slang words with actual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "Ih7_FK3Desux",
    "outputId": "e59f5aea-f5fe-4d37-e591-8e2267eb4c30"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-b6a96aea-7fb2-4a55-9fde-7d1af7eb9ecf\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-b6a96aea-7fb2-4a55-9fde-7d1af7eb9ecf\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Untitled.ipynb to Untitled.ipynb\n",
      "Saving neg.txt to neg.txt\n",
      "Saving pos.txt to pos.txt\n",
      "Saving slang.txt to slang.txt\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cZ9JsyWLeR1I"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bS4J0G44eR1L"
   },
   "outputs": [],
   "source": [
    "random.seed(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UP_yuflweR1O"
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = RegexpTokenizer('[a-zA-Z0-9]\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NYkgEEvDeR1R"
   },
   "outputs": [],
   "source": [
    "positive = []\n",
    "negative = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9oKapuHQeR1U"
   },
   "outputs": [],
   "source": [
    "with open('pos.txt', 'r', buffering = 1000, encoding=\"ISO-8859–1\") as p:\n",
    "    positive = p.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r5PORwCqeR1X"
   },
   "outputs": [],
   "source": [
    "with open('neg.txt', 'r', buffering = 1000, encoding=\"ISO-8859–1\") as n:\n",
    "    negative = n.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qJmg9bzrozON"
   },
   "source": [
    "### As, generating labels for the whole 1600000 tweets is taking around 8hrs on Google Collab GPU, I had to reduce the dataset to a max of 400000 tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qthAxGKIntdN"
   },
   "outputs": [],
   "source": [
    "positive = positive[:200000]\n",
    "negative = negative[:200000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7HKk1y_HeR1Z",
    "outputId": "5a2c63b9-f3dd-44e4-cc10-a36b228c221b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling tweets to maintain randomness....\n"
     ]
    }
   ],
   "source": [
    "print('Shuffling tweets to maintain randomness....')\n",
    "unclean_tweets = list(positive) + list(negative)\n",
    "random.shuffle(unclean_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "wFfAaATGeR1f",
    "outputId": "b8302987-3b31-4f92-c658-913703c8b340"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 47/400000 [00:00<14:21, 463.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate labels...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [13:41<00:00, 486.73it/s]\n"
     ]
    }
   ],
   "source": [
    "print('Generate labels...')\n",
    "labels = []\n",
    "with tqdm(total = len(unclean_tweets)) as pb:\n",
    "    for tweet in unclean_tweets:\n",
    "        if tweet in positive:\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "        pb.update(1)\n",
    "del positive\n",
    "del negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "2YdamiTzeR1j",
    "outputId": "a465d2be-af1e-4c6e-e85b-c35ede8923fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I am falling in love with the Backstreet boys all over again!! I finally see what everyone loves about Nick  Damn he's hot\\n\",\n",
       " 'who here wants to see a seventh hockey team in Canada? \\n',\n",
       " \"Finished registering for sw. today was fun in design. lots'olaughs w/Katrina, Jackie, Sandra&amp;Angelo &quot;HOT DAMN!&quot; Finishing drawing project \\n\",\n",
       " '@PeachPosh dont do it! \\n',\n",
       " 'neil Young is helpless  ? http://blip.fm/~6svev\\n']"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unclean_tweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "zyYRQL8FsoPn",
    "outputId": "1e273d78-05ca-423b-dee2-9d5cc7abe0b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweet-preprocessor\n",
      "  Downloading https://files.pythonhosted.org/packages/2a/f8/810ec35c31cca89bc4f1a02c14b042b9ec6c19dd21f7ef1876874ef069a6/tweet-preprocessor-0.5.0.tar.gz\n",
      "Building wheels for collected packages: tweet-preprocessor\n",
      "  Running setup.py bdist_wheel for tweet-preprocessor ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/1b/27/cc/49938e98a2470802ebdefae9d2b3f524768e970c1ebbe2dc4a\n",
      "Successfully built tweet-preprocessor\n",
      "Installing collected packages: tweet-preprocessor\n",
      "Successfully installed tweet-preprocessor-0.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tweet-preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6FcOG-v2tq3w"
   },
   "outputs": [],
   "source": [
    "# tweet preprocessor to eliminate emoji, url and mentions\n",
    "import preprocessor as p\n",
    "p.set_options(p.OPT.URL, p.OPT.EMOJI, p.OPT.MENTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9yNadvvBvuQX"
   },
   "source": [
    "## Cleaning tweets\n",
    "### 1. Remove emoji\n",
    "### 2. Remove URLs\n",
    "### 3. Remove mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xKog4vgku53p",
    "outputId": "7d735fd8-ad9c-40fe-ffcf-89fd3e7bf86a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [00:19<00:00, 20421.56it/s]\n"
     ]
    }
   ],
   "source": [
    "with tqdm(total = len(unclean_tweets)) as pb:\n",
    "    for i in range(len(unclean_tweets)):\n",
    "      tweet_unclean = unclean_tweets[i]\n",
    "      unclean_tweets[i] = p.clean(tweet_unclean)\n",
    "      pb.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "H57f-EZiviLu",
    "outputId": "dd15442d-5cca-4081-8a8f-3c6e85ac630b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I am falling in love with the Backstreet boys all over again!! I finally see what everyone loves about Nick Damn he's hot\",\n",
       " 'who here wants to see a seventh hockey team in Canada?',\n",
       " \"Finished registering for sw. today was fun in design. lots'olaughs w/Katrina, Jackie, Sandra&amp;Angelo &quot;HOT DAMN!&quot; Finishing drawing project\",\n",
       " 'dont do it!',\n",
       " 'neil Young is helpless ?']"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unclean_tweets[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1UNjzmU3w6zR"
   },
   "source": [
    "### We see that there are certain tweets where the HTML encoding has not been converted into text. Eg: &amp, &quot\n",
    "### So, here I will use BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GwavPW8nwEcL",
    "outputId": "6ac847eb-9877-450e-dcd5-26f5a447f2d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lots\\'olaughs w/Katrina, Jackie, Sandra&Angelo \"HOT DAMN!\"'"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "sample = BeautifulSoup(\"lots'olaughs w/Katrina, Jackie, Sandra&amp;Angelo &quot;HOT DAMN!&quot;\")\n",
    "sample.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "H-eRSm_81OmS",
    "outputId": "a979d133-d688-4eb0-cf2f-6819d68502c1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 185088/400000 [00:18<00:22, 9668.02it/s]/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:273: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "100%|██████████| 400000/400000 [00:40<00:00, 9863.08it/s]\n"
     ]
    }
   ],
   "source": [
    "with tqdm(total = len(unclean_tweets)) as pb:\n",
    "    for i in range(len(unclean_tweets)):\n",
    "      tweet_unclean = unclean_tweets[i]\n",
    "      unclean_tweets[i] = BeautifulSoup(tweet_unclean, 'lxml').get_text()\n",
    "      pb.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "c-l9mYNq1uMQ",
    "outputId": "16cb5b41-8475-4d2d-a619-50a15b1cb89a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I am falling in love with the Backstreet boys all over again!! I finally see what everyone loves about Nick Damn he's hot\",\n",
       " 'who here wants to see a seventh hockey team in Canada?',\n",
       " 'Finished registering for sw. today was fun in design. lots\\'olaughs w/Katrina, Jackie, Sandra&Angelo \"HOT DAMN!\" Finishing drawing project',\n",
       " 'dont do it!',\n",
       " 'neil Young is helpless ?']"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unclean_tweets[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yw_ADGIa2xSU"
   },
   "source": [
    "### Tokenizing tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RAMIyCmX2HlJ",
    "outputId": "b0b812f4-79d3-4def-db5a-a901f6fb98ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing ..\n"
     ]
    }
   ],
   "source": [
    "print('Tokenizing ..')\n",
    "tweets = [tokenizer.tokenize(tweet.lower()) for tweet in unclean_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "sF3MJvOh24NL",
    "outputId": "cc09fed5-080b-4e21-ba9a-9ac36cbce2e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['am',\n",
       "  'falling',\n",
       "  'in',\n",
       "  'love',\n",
       "  'with',\n",
       "  'the',\n",
       "  'backstreet',\n",
       "  'boys',\n",
       "  'all',\n",
       "  'over',\n",
       "  'again',\n",
       "  'finally',\n",
       "  'see',\n",
       "  'what',\n",
       "  'everyone',\n",
       "  'loves',\n",
       "  'about',\n",
       "  'nick',\n",
       "  'damn',\n",
       "  'he',\n",
       "  'hot'],\n",
       " ['who',\n",
       "  'here',\n",
       "  'wants',\n",
       "  'to',\n",
       "  'see',\n",
       "  'seventh',\n",
       "  'hockey',\n",
       "  'team',\n",
       "  'in',\n",
       "  'canada']]"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FKM2SlVW3WdK"
   },
   "source": [
    "### Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "9ZUrEiSW3zZj",
    "outputId": "a071b72e-7805-4ab8-bbc4-e8a728b57c10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6vhHMGYk3H67",
    "outputId": "e5b5db7e-bb59-4196-def0-5d8c32a12702"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [02:10<00:00, 3057.61it/s]\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "with tqdm(total=len(unclean_tweets)) as pb:\n",
    "    for tweet in unclean_tweets:\n",
    "        lemmatized = [lemmatizer.lemmatize(word) for word in tweet]\n",
    "        tweets.append(lemmatized)\n",
    "        pb.update(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jeSCxF_D5tWx"
   },
   "source": [
    "## Word2Vec algorithm for word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CvB9O5EG3qih"
   },
   "outputs": [],
   "source": [
    "vector_size = 256\n",
    "window = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 734
    },
    "colab_type": "code",
    "id": "BvFxIT9j6HNx",
    "outputId": "985fba0e-6339-41fa-fec8-4b87b494ac1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/a4/d10c0acc8528d838cda5eede0ee9c784caa598dbf40bd0911ff8d067a7eb/gensim-3.6.0-cp36-cp36m-manylinux1_x86_64.whl (23.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 23.6MB 1.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.6)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
      "Collecting smart-open>=1.2.1 (from gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/4b/1f/6f27e3682124de63ac97a0a5876da6186de6c19410feab66c1543afab055/smart_open-1.7.1.tar.gz\n",
      "Collecting boto>=2.32 (from smart-open>=1.2.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/10/c0b78c27298029e4454a472a1919bde20cb182dab1662cec7f2ca1dcc523/boto-2.49.0-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.4MB 15.5MB/s \n",
      "\u001b[?25hCollecting bz2file (from smart-open>=1.2.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
      "Collecting boto3 (from smart-open>=1.2.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/01/7d129a9f03df402234e2d469d73ad8d1a8c7decdc3bd4b7625beea9e0b82/boto3-1.9.47-py2.py3-none-any.whl (128kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 26.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.10.15)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
      "Collecting botocore<1.13.0,>=1.12.47 (from boto3->smart-open>=1.2.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/69/62adb21d6af91ca1128c529112cd82570689186cafa7b7978a494739ddfd/botocore-1.12.47-py2.py3-none-any.whl (4.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 4.8MB 4.0MB/s \n",
      "\u001b[?25hCollecting s3transfer<0.2.0,>=0.1.10 (from boto3->smart-open>=1.2.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/14/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d/s3transfer-0.1.13-py2.py3-none-any.whl (59kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 23.5MB/s \n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.2.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n",
      "Collecting docutils>=0.10 (from botocore<1.13.0,>=1.12.47->boto3->smart-open>=1.2.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\n",
      "\u001b[K    100% |████████████████████████████████| 552kB 18.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.47->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
      "Building wheels for collected packages: smart-open, bz2file\n",
      "  Running setup.py bdist_wheel for smart-open ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/23/00/44/e5b939f7a80c04e32297dbd6d96fa3065af89ecf57e2b5f89f\n",
      "  Running setup.py bdist_wheel for bz2file ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
      "Successfully built smart-open bz2file\n",
      "Installing collected packages: boto, bz2file, docutils, jmespath, botocore, s3transfer, boto3, smart-open, gensim\n",
      "Successfully installed boto-2.49.0 boto3-1.9.47 botocore-1.12.47 bz2file-0.98 docutils-0.14 gensim-3.6.0 jmespath-0.9.3 s3transfer-0.1.13 smart-open-1.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "L5-llXJw52-1",
    "outputId": "f5d271c4-03e9-4d56-9739-76f868b6282b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Word2Vec Vectors ..\n",
      "Word2Vec Created in 1022.3702681064606 seconds.\n",
      "Word2Vec Model saved at word2vec.model\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import time\n",
    "\n",
    "word2vec_model = 'word2vec.model'\n",
    "\n",
    "print('Generating Word2Vec Vectors ..')\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model = Word2Vec(sentences=tweets, size=vector_size, window=window, negative=20, iter=50, workers=4)\n",
    "\n",
    "print('Word2Vec Created in {} seconds.'.format(time.time() - start))\n",
    "\n",
    "model.save(word2vec_model)\n",
    "print('Word2Vec Model saved at {}'.format(word2vec_model))\n",
    "\n",
    "#Clear the memory!\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mJrdIUDO6DDM"
   },
   "outputs": [],
   "source": [
    "# load the saved model to store the vectors\n",
    "model = Word2Vec.load('word2vec.model')\n",
    "x_vectors = model.wv\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T7yP9d2MEoXk"
   },
   "source": [
    "### Train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "E2nEtd56DLE7",
    "outputId": "e87ff8b9-ee84-4eb8-a298-bbb6dc4d406c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.6)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.11.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.14.6)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Hu4zrASyFHvC",
    "outputId": "1a2fcfcf-9e24-4ce8-d9d7-8ad876b4a3c7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras.backend as kb\n",
    "\n",
    "train_size = int(0.9*(len(tweets)))\n",
    "test_size = int(0.1*(len(tweets)))\n",
    "\n",
    "max_no_tokens = 15\n",
    "\n",
    "indexes = set(np.random.choice(len(tweets), train_size + test_size, replace=False))\n",
    "\n",
    "x_train = np.zeros((train_size, max_no_tokens, vector_size), dtype=kb.floatx())\n",
    "y_train = np.zeros((train_size, 2), dtype=np.int32)\n",
    "\n",
    "x_test = np.zeros((test_size, max_no_tokens, vector_size), dtype=kb.floatx())\n",
    "y_test = np.zeros((test_size, 2), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pNVtQdlaFUkv"
   },
   "outputs": [],
   "source": [
    "for i, index in enumerate(indexes):\n",
    "    for t, token in enumerate(tweets[index]):\n",
    "        if t >= max_no_tokens:\n",
    "            break\n",
    "      \n",
    "        if token not in x_vectors:\n",
    "            continue\n",
    "    \n",
    "        if i < train_size:\n",
    "            x_train[i, t, :] = x_vectors[token]\n",
    "        else:\n",
    "            x_test[i - train_size, t, :] = x_vectors[token]\n",
    "\n",
    "  \n",
    "    if i < train_size:\n",
    "        y_train[i, :] = [1.0, 0.0] if labels[index] == 0 else [0.0, 1.0]\n",
    "    else:\n",
    "        y_test[i - train_size, :] = [1.0, 0.0] if labels[index] == 0 else [0.0, 1.0]\n",
    "    \n",
    "del tweets\n",
    "del labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7zgtjHp1FZ6Q",
    "outputId": "afa724a3-e2bb-4249-cdc7-eb0d837343c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360000, 15, 256), (360000, 2), (40000, 15, 256), (40000, 2))"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gKHiewVGF-K_"
   },
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "no_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "P_B8ZufkGMx-",
    "outputId": "2b223fa1-231a-4112-b980-837ddbde2e59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 15, 32)            24608     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 15, 32)            3104      \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 15, 32)            3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5, 32)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 1024)              2232320   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 3,314,274\n",
      "Trainable params: 3,314,274\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Dropout, Dense, Flatten, LSTM, MaxPooling1D, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(32, kernel_size=3, activation='elu', padding='same',\n",
    "                 input_shape=(max_no_tokens, vector_size)))\n",
    "model.add(Conv1D(32, kernel_size=3, activation='elu', padding='same'))\n",
    "model.add(Conv1D(32, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "\n",
    "model.add(Bidirectional(LSTM(512, dropout=0.2, recurrent_dropout=0.3)))\n",
    "\n",
    "model.add(Dense(512, activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='sigmoid'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(512, activation='sigmoid'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='logs/', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "id": "5fCSMYm_GOaG",
    "outputId": "4c93189c-f4e4-4a4a-fddf-f3f0e9daa46c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 360000 samples, validate on 40000 samples\n",
      "Epoch 1/100\n",
      "360000/360000 [==============================] - 57s 158us/step - loss: 0.5994 - acc: 0.6712 - val_loss: 0.5966 - val_acc: 0.6731\n",
      "Epoch 2/100\n",
      "360000/360000 [==============================] - 57s 157us/step - loss: 0.5988 - acc: 0.6723 - val_loss: 0.5980 - val_acc: 0.6729\n",
      "Epoch 3/100\n",
      "360000/360000 [==============================] - 57s 158us/step - loss: 0.5976 - acc: 0.6727 - val_loss: 0.5944 - val_acc: 0.6748\n",
      "Epoch 4/100\n",
      "360000/360000 [==============================] - 57s 157us/step - loss: 0.5970 - acc: 0.6738 - val_loss: 0.5952 - val_acc: 0.6741\n",
      "Epoch 5/100\n",
      "360000/360000 [==============================] - 57s 159us/step - loss: 0.5966 - acc: 0.6739 - val_loss: 0.5943 - val_acc: 0.6763\n",
      "Epoch 6/100\n",
      "360000/360000 [==============================] - 58s 162us/step - loss: 0.5958 - acc: 0.6743 - val_loss: 0.5964 - val_acc: 0.6733\n",
      "Epoch 7/100\n",
      "360000/360000 [==============================] - 59s 163us/step - loss: 0.5951 - acc: 0.6752 - val_loss: 0.5927 - val_acc: 0.6772\n",
      "Epoch 8/100\n",
      "360000/360000 [==============================] - 59s 164us/step - loss: 0.5943 - acc: 0.6759 - val_loss: 0.5919 - val_acc: 0.6776\n",
      "Epoch 9/100\n",
      "360000/360000 [==============================] - 59s 163us/step - loss: 0.5935 - acc: 0.6771 - val_loss: 0.5927 - val_acc: 0.6792\n",
      "Epoch 10/100\n",
      "360000/360000 [==============================] - 59s 163us/step - loss: 0.5931 - acc: 0.6775 - val_loss: 0.5928 - val_acc: 0.6778\n",
      "Epoch 11/100\n",
      "360000/360000 [==============================] - 59s 164us/step - loss: 0.5922 - acc: 0.6779 - val_loss: 0.5959 - val_acc: 0.6731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe42630e278>"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=batch_size, shuffle=True, epochs=no_epochs,\n",
    "         validation_data=(x_test, y_test), callbacks=[tensorboard, EarlyStopping(min_delta=0.0001, patience=3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mbUSkRFRPvhU"
   },
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "m8yOfh94G_6p",
    "outputId": "2d285005-329f-41ea-ca09-bfb18c1dba4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "IKPRoZtAPygt",
    "outputId": "516ace12-8e81-41fb-aadc-d738fd83fa6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 19s 486us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5958784397602082, 0.673075]"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=x_test, y=y_test, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z-V8qLk8P492"
   },
   "outputs": [],
   "source": [
    "model.save('word2vec-twitter-sentiment.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 948
    },
    "colab_type": "code",
    "id": "crWzPbeFQNa4",
    "outputId": "560f1ac4-364d-40b1-8301-85b2c61ee4d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception happened during processing of request from ('::ffff:127.0.0.1', 45998, 0, 0)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/lib/python3.6/http/server.py\", line 418, in handle\n",
      "    self.handle_one_request()\n",
      "  File \"/usr/lib/python3.6/http/server.py\", line 406, in handle_one_request\n",
      "    method()\n",
      "  File \"/usr/lib/python3.6/http/server.py\", line 639, in do_GET\n",
      "    self.copyfile(f, self.wfile)\n",
      "  File \"/usr/lib/python3.6/http/server.py\", line 800, in copyfile\n",
      "    shutil.copyfileobj(source, outputfile)\n",
      "  File \"/usr/lib/python3.6/shutil.py\", line 82, in copyfileobj\n",
      "    fdst.write(buf)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 800, in write\n",
      "    self._sock.sendall(b)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "MessageError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-0f7296e5fc7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'word2vec-twitter-sentiment.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMessageError\u001b[0m: Error: Failed to download: TypeError: Failed to fetch"
     ]
    }
   ],
   "source": [
    "files.download('word2vec-twitter-sentiment.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gvXEW-3oUHkz"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ued2baBAQyb8"
   },
   "outputs": [],
   "source": [
    "files.download('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ox0o9M6XRIzz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Word2Vec Implementation.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
